{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11271b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch\n",
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "#Intro to Tensors In Pytorch / Numpy\n",
    "\n",
    "import torch #overall lib\n",
    "print(torch.__name__) #prints out attributes\n",
    "print(torch.__version__) #prints the torch version\n",
    "\n",
    "#a tensor is just a multi-dimentional array. (a little more complex but whatevs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b1356b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the scalar is 1, with dimensions: 0, shape torch.Size([]), and type torch.int32, can return item with 1\n"
     ]
    }
   ],
   "source": [
    "#lets create a scalar in pytorch\n",
    "scalar = torch.tensor(data=1,dtype=torch.int32) #defaults to teh number provided. torch.tensor(the factory function to create a tensor from data) vs torch.Tensor (the class)\n",
    "print(f\"the scalar is {scalar}, with dimensions: {scalar.ndim}, shape {scalar.shape}, and type {scalar.dtype}, can return item with {scalar.item()}\")\n",
    "#note: this will return dim 0 but data = [1] is dim 1 (not a scalar anymore)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5343653d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Size([4]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensors: Rank/Order = in linalg the number of vectors in the basis of column space or row space(for a matrix) but in the context or tensors its just\n",
    "#another way of saying dim. ie a dim 3 tensors means its Rank is also 3\n",
    "\n",
    "vector = torch.tensor(data=[1,2,3,4]) #NOTE: in Linalg, this vector is Dim4 since it is is R4, however we consider this a dim 1 object\n",
    "vector.ndim,vector.shape #predict ndim is 1, and shape is [4], note that torch.Size is an Listlike object (indexable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0796e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix:\n",
    "\n",
    "MATRIX = torch.tensor(data=[[1,2],[3,4]],dtype=torch.int32) #will be 2dim object, also by convention make it all caps\n",
    "MATRIX.ndim, MATRIX.shape # note the indexes in row major order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80677f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 2]), 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TENSOR\n",
    "#broadly, torch.tensor is just a function that makes tensors, but in the case that the data is a tensor itself, like torch.tensor(x)\n",
    "#it is preferred to do x.clone().detach() clone means they do not share memory with the og tensor, and detach means they are detached from the computational\n",
    "#graph\n",
    "#torch.tensor is just torch.Tensor.clone().detach()\n",
    "#torch.as_tensor() is better when you dont want to copy the data, and can instead wrap it as a tensor (usually a list ndim list or numpy array or something)\n",
    "\n",
    "#If I use x in some computation that leads to a scalar loss, and I call loss.backward(), PyTorch should compute x.grad. (thats what requiresgrad means)\n",
    "#it auto calls loss.backwards() on the tensors when computing the grad\n",
    "\n",
    "#exe:\n",
    "a = torch.randn(size=(2,2),requires_grad=True,dtype=torch.float32)\n",
    "b = a * 2\n",
    "c = b.sum()\n",
    "c.backward()\n",
    "print(a.grad) #cannot do b.grad since b is not a leaf node, and autograd only calculates grad relative to leaf nodes\n",
    "print(a.grad_fn)\n",
    "\n",
    "\n",
    "TENSOR = torch.tensor([[[1,2],[3,4]],[[5,6],[7,8]]]) #size 2,2,2\n",
    "TENSOR.shape, TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc7ae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ML process starts with random tensor and slowly adjusts it based on data.\n",
    "#first initialize a random tensor of values, then based on some data adjust the tensors so they better reflect patterns in the data\n",
    "\n",
    "random_tensor = torch.rand(size=(3,2))\n",
    "random_tensor.shape,random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0716dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero tensor:\n",
    "zeros = torch.zeros(size=(3,2))\n",
    "zeros_like = torch.zeros_like(random_tensor)\n",
    "\n",
    "#one tensors\n",
    "ones = torch.ones(size=(3,2))\n",
    "ones_like = torch.ones_like(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d1fe724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 3, 5, 7, 9]), torch.Size([5]), 1, torch.int64, device(type='cpu'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the arange function to make a 1dim tensor of a list/range\n",
    "import numpy as np\n",
    "elements = torch.arange(start=1,end=10,step=2)\n",
    "#as a numpy array:\n",
    "nump = np.array(elements) #thats how to do it\n",
    "elements.device\n",
    "\n",
    "#all useful params\n",
    "elements,elements.shape, elements.ndim, elements.dtype, elements.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1fd6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 4],\n",
      "        [5, 7],\n",
      "        [2, 7]]) \n",
      "\n",
      " tensor([[7, 4],\n",
      "        [6, 9],\n",
      "        [4, 9]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[79, 90, 72],\n",
       "        [63, 93, 83],\n",
       "        [42, 75, 71]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tensor operations\n",
    "\n",
    "a = torch.randint(low=1,high=10,size=(3,2)) # doesn't appear the autocomplete\n",
    "b = torch.randint_like(a,low=1,high=10)\n",
    "#addition\n",
    "print(a,\"\\n\\n\",b)\n",
    "a + b\n",
    "\n",
    "#multiplication:\n",
    "a * b #elementwise, can also use torch.mul and torch.add to do same\n",
    "\n",
    "#matrix multiplication:\n",
    "torch.matmul(a,b.T) #ensure dims match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127f72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1216,  0.5397, -0.3450, -1.7290],\n",
      "         [ 0.7293,  0.9217, -1.3062,  2.0650],\n",
      "         [-0.6160,  0.7263, -0.9313,  0.5312]],\n",
      "\n",
      "        [[-0.0391,  0.8063,  0.2621,  1.2398],\n",
      "         [ 0.0600,  0.2732, -0.3274, -0.5025],\n",
      "         [ 0.2304, -0.8531, -0.1790,  0.4482]]])\n",
      "tensor([[[ 0.1216,  0.5397, -0.3450, -1.7290],\n",
      "         [ 0.7293,  0.9217, -1.3062,  2.0650],\n",
      "         [-0.6160,  0.7263, -0.9313,  0.5312]],\n",
      "\n",
      "        [[-0.0391,  0.8063,  0.2621,  1.2398],\n",
      "         [ 0.0600,  0.2732, -0.3274, -0.5025],\n",
      "         [ 0.2304, -0.8531, -0.1790,  0.4482]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n1/0nnckscj36xfsjzb_6z3y0ym0000gn/T/ipykernel_88566/3815888309.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.dot(torch.flatten(torch.tensor(a,dtype=torch.float)),torch.flatten(b.broadcast_to(size=a.shape)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2312, -5.7378],\n",
       "        [11.1559, -1.6394],\n",
       "        [15.6182, -6.5575]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Broadcasting\n",
    "\n",
    "#operations like addition and multiplication can be done for any matricies whose sizes are broadcastable\n",
    "\n",
    "#broadcastable, if all dims are equal or one of them is equal to one:\n",
    "#exe size (3,2) and (3,1) are broadcastable, since just copies the (3,1) to (3,2) easily\n",
    "#exe size (3) and (3,2) also works since can just unsqueeze then broadcast\n",
    "\n",
    "a = torch.randint(low=1,high=10,size=(3,2))\n",
    "b = torch.randn(size=(2,)) #NOTE: pytorch PREPENDS but doesnt postpend, so (3,2) and (2,) is good, but not (3,2) , (3)!\n",
    "\n",
    "#if you want that to work, you will have to manually unqsqueeze dim=1 and then it should work\n",
    "\n",
    "#how to go from tensor to int tuple: \n",
    "torch.dot(torch.flatten(torch.tensor(a,dtype=torch.float)),torch.flatten(b.broadcast_to(size=a.shape)))\n",
    "\n",
    "#Transpose vs Permute: permute reorders\n",
    "\n",
    "\n",
    "c = torch.randn(size=(2,3,4)) \n",
    "print(c)\n",
    "torch.transpose(c,dim0=1,dim1=2) #transpose .T works only when 2 dims, other transpose just swaps two dims, and permute swaps all dim\n",
    "#Functionally, whats happening is a change in stride!\n",
    "\n",
    "print(c)\n",
    "\n",
    "torch.mul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a0514a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stride and Storage in memory explanation\n",
    "\n",
    "# reshape changes the stride aswell, just keeps it in order\n",
    "\n",
    "#exe: lets suppose you create some tensor\n",
    "torch.manual_seed(42)\n",
    "random_tensor = torch.tensor(data=[[[1,2],[3,4]],[[5,6],[7,8]]]) #this is a size 2,2,2 tensor, \n",
    "random_tensor\n",
    "\n",
    "#However, in memory it is stored continuously in row-major order like this (since memory is 1D)\n",
    "#Row major order just means that the highest dimension moves the fastest, so in order\n",
    "# tensor[0][0][0], [0][0][1], [0][1][0], [0][1][1] ...\n",
    "#the \"highest dimension\", dim=2 is the one on the end, which corresponds to which part in the yellow it is\n",
    "# so, in memory it is stored as:\n",
    "# 1,2,3,4,5,6,7,8 \n",
    "\n",
    "#now, whenever you do any tensor manipulations to it, be that a transpose, a permute, a reshape, or whatever, we want to avoid\n",
    "#making a new tensor since that is very costly, O(n), since we will anyways no longer need the og tensor.\n",
    "#instead, we can get away with just changing the stride!\n",
    "\n",
    "#functionally, when you write rand_tensor[0][1][0], what the computer does, like for arrays, it adds some offset to each index\n",
    "# or &rand_tensor[0] + 0(2*2) + 1 * (2) + 0(1), where the parenthesis the \"stride\", corresponding to how many indices down the list\n",
    "# you gotta move to find it\n",
    "\n",
    "#in a reshape/view, you are just changing the strides, ensuring that the number of elements is conserved. \n",
    "#sidenote: reshape is just a view that will copy if necessary (ie if no longer in row major)\n",
    "# so, for a (2,2,2), you can very easily create a new tensor using tensor.reshape, which can share the data with the og tensor, only\n",
    "#instead it has a different stride.\n",
    "\n",
    "#IN a transpose however, you are making the strides non-contiguous, like (1,2,4), which means it is no longer in row-major order\n",
    "\n",
    "#MASSIVE NOTE: if from here, ie after a transpose/permute, you descide to reshape, it is forced to copy the data since \n",
    "#if you just change the stride, it will be the reshape of the untransposed tensor, not the new one:\n",
    "\n",
    "#exe: initially stride is (4,2,1) for\n",
    "# 1,2,3,4,5,6,7,8\n",
    "#if you permute (2,1,0), new stride is (1,2,4) so \n",
    "#[0][0][1] will be the 4th element down the list, or 5, but the data is unchanged\n",
    "#however, if i now ask for a resize, and you just change the stride as per usual, it will not be correct since (8,1,1) for exe will \n",
    "#only be correct for the og tensor, so you have to copy the data back in to row-major order, and THEN apply the reshape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a7b016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 4],\n",
      "        [3, 8],\n",
      "        [1, 6]]) tensor([[5, 3],\n",
      "        [7, 1],\n",
      "        [5, 5]])\n"
     ]
    }
   ],
   "source": [
    "#Matrix Multiplication\n",
    "\n",
    "#for transpose, torch.transpose(x,dim0,dim1) to swap them, or .T\n",
    "\n",
    "a = torch.randint(low=1,high=10,size=(3,2))\n",
    "b = torch.randint_like(a,low=a.min(),high=a.max())\n",
    "print(a,b)\n",
    "\n",
    "c = a.matmul(b.T)\n",
    "\n",
    "#Matmul in higher dims:\n",
    "\n",
    "#for (10,3,2) matmul by (10,2,3), treated as 10 matrix multiplications, meaning resulting object is (10,2,2) \n",
    "# for for (2,3,4,5,6) times (2,3,4,6,5), it results in (2,3,4,5,5) or a complex tensor or matrix multiplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be64cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n1/0nnckscj36xfsjzb_6z3y0ym0000gn/T/ipykernel_88566/3147962098.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  a.min(),a.max(), a.sum(),torch.tensor(a,dtype=torch.float).mean() # these return tensors themselves, useful for backprop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 4,  8,  4,  9],\n",
       "          [10,  9,  3,  6]],\n",
       " \n",
       "         [[ 6,  5,  9,  2],\n",
       "          [ 8, 10,  3,  7]],\n",
       " \n",
       "         [[ 9,  3,  9,  3],\n",
       "          [ 2,  1,  1,  7]]]),\n",
       " tensor([[1, 1, 0, 0],\n",
       "         [1, 1, 0, 1],\n",
       "         [0, 0, 0, 1]]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now for general torch functions\n",
    "\n",
    "a = torch.arange(start=1,end=20,step=2)\n",
    "a.min(),a.max(), a.sum(),torch.tensor(a,dtype=torch.float).mean() # these return tensors themselves, useful for backprop\n",
    "# a.backward() will calculate teh a.grad() for each of the values\n",
    "\n",
    "#argmax, what it does is it returns the index of the largest value in a tensor\n",
    "\n",
    "a.argmax().item() # element 9 has the largest value\n",
    "\n",
    "#for 2d tensor\n",
    "b,b.shape,b.argmax(dim=1),b.argmax(dim=0) #argmax by itself, not sure what it does in higher dims, but when you specify a dimension, it flattens the\n",
    "#tensor in that dimension, and instead replaces it with the subtensor with teh index of the larger value\n",
    "\n",
    "\n",
    "#ie for b.argmax(dim=1), assuming teh object is of shape (3,2,2)\n",
    "#for the dimensions lower than dim, it is just describing the shape of teh object, ie it will repeat the task for all of them\n",
    "#for the dimension in question, it will vary it whilst keeping the higher dims constant, and then select the max value, and set it at\n",
    "#the new position (upperdim,lower dim, lower dim) with the dim in question missing\n",
    "\n",
    "#exe\n",
    "a = torch.randint(size=(3,2,4),low=1,high=11)\n",
    "a,a.argmax(dim=1)\n",
    "\n",
    "#here dim=1 is the dim in question, so the 0th dimension will just be kept as is and this process will be done for all iterations of it\n",
    "#on the subtensors, so output is (3,...)\n",
    "\n",
    "# then at the dim in question REMEMBER IT IS NOT ASKING TO FIND THE BIGGEST ELEMENT IN EACH ROW, BUT THE BIGGEST ELEMENT ACROSS ROWS\n",
    "#thus it will start with [0][i][0] and for all i's possible, and find the max. Then, this max will be put at (0,0)\n",
    "#then it will try  [0][i][1], find teh max and put it at [0][1] of the result\n",
    "# it will repeat this process untill it obtains \n",
    "\n",
    "# exe\n",
    "#start with 0 for 0th dim, compare ACROSS rows\n",
    "#10 > 4, so [3,0] is 1, 9 > 8 so [3,1] is 1 untill you get [1,1,0,0]\n",
    "#then repeat with [1] and [2] and thats the result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same with stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0431, -1.6047],\n",
      "         [ 1.7878, -0.4780],\n",
      "         [-0.2429, -0.9342]],\n",
      "\n",
      "        [[-0.2483, -1.2082],\n",
      "         [-2.3169, -0.2168],\n",
      "         [-1.3847, -0.8712]],\n",
      "\n",
      "        [[-0.2234,  1.7174],\n",
      "         [ 0.3189, -0.4245],\n",
      "         [-0.8286,  0.3309]],\n",
      "\n",
      "        [[-1.5576,  0.9956],\n",
      "         [-0.8798, -0.6011],\n",
      "         [-1.2742,  2.1228]]])\n",
      "tensor([[-0.0431, -1.6047],\n",
      "        [ 1.7878, -0.4780],\n",
      "        [-0.2429, -0.9342],\n",
      "        [-0.2483, -1.2082],\n",
      "        [-2.3169, -0.2168],\n",
      "        [-1.3847, -0.8712],\n",
      "        [-0.2234,  1.7174],\n",
      "        [ 0.3189, -0.4245],\n",
      "        [-0.8286,  0.3309],\n",
      "        [-1.5576,  0.9956],\n",
      "        [-0.8798, -0.6011],\n",
      "        [-1.2742,  2.1228]])\n",
      "tensor([[-0.0431, -1.6047],\n",
      "        [ 1.7878, -0.4780],\n",
      "        [-0.2429, -0.9342],\n",
      "        [-0.2483, -1.2082],\n",
      "        [-2.3169, -0.2168],\n",
      "        [-1.3847, -0.8712],\n",
      "        [-0.2234,  1.7174],\n",
      "        [ 0.3189, -0.4245],\n",
      "        [-0.8286,  0.3309],\n",
      "        [-1.5576,  0.9956],\n",
      "        [-0.8798, -0.6011],\n",
      "        [-1.2742,  2.1228]])\n"
     ]
    }
   ],
   "source": [
    "#reshape, view, transpose, stack, unsqueeze, squeeze, from_numpy, \n",
    "torch.manual_seed(42)\n",
    "tensor = torch.randint(size=(3,2),low=1,high=14)\n",
    "tensor2 = tensor.type(torch.float32)# NOTE: use type to return teh tensor just with a new type\n",
    "\n",
    "tensor1 = torch.randn(size=(4,3,2))\n",
    "print(tensor1)\n",
    "tensor2 = tensor1.reshape(shape=(12,2)) #perfectly valid, doesn't need to keep dimensions\n",
    "print(tensor2)\n",
    "tensor3 = torch.Tensor.view(tensor1,size=(12,2))\n",
    "print(tensor3)\n",
    "\n",
    "#as for stacking, that works by inserting a dimension and moving the other ones aside. so when stacking two (3,2)s at dim=1\n",
    "#you will be creating a (3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24858e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also, the == or .eq is useful for obtaining a tensor of booleans (useful for accuracy function and stuff like that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553033d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3930,  0.4327],\n",
      "        [-1.3627,  1.3564],\n",
      "        [ 0.6688, -0.7077]])\n",
      "OrderedDict({'weight': tensor([[ 0.5406,  0.5869],\n",
      "        [-0.1657,  0.6496],\n",
      "        [-0.1549,  0.1427],\n",
      "        [-0.3443,  0.4153],\n",
      "        [ 0.6233, -0.5188],\n",
      "        [ 0.6146,  0.1323]]), 'bias': tensor([ 0.5224,  0.0958,  0.3410, -0.0998,  0.5451,  0.1045])})\n",
      "tensor([[ 0.9888,  0.3117,  0.3418, -0.0555,  0.5656,  0.4033],\n",
      "        [ 0.5818,  1.2026,  0.7456,  0.9326, -1.0080, -0.5535],\n",
      "        [ 0.4686, -0.4747,  0.1364, -0.6240,  1.3291,  0.4219]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "0.98837473 should be the same as 0.9888474941253662, which is is\n"
     ]
    }
   ],
   "source": [
    "#Now finally for the linear layer:\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "layer = torch.nn.Linear(in_features=2,out_features=6) #stores a 6 by 2 matrix internally, then multiplies by the transpose or a (2,6) which\n",
    "#takes a matrix with 2 features to 6 featues in the last element\n",
    "x = torch.randn(size=(3,2))\n",
    "\n",
    "#functionally, then input, is a tensor, but can really be thought of as a bunch of vectors of size 2 (the input size)\n",
    "# from here, we will be multiplying that vector by the weights\n",
    "print(x)\n",
    "print(layer.state_dict())\n",
    "output = layer(x)\n",
    "print(output)\n",
    "\n",
    "output_1_same = 0.3930*0.5406 + 0.4327*0.5859 + 0.5224\n",
    "print(f\"{output_1_same} should be the same as {output[0][0]}, which it {\"is\" if abs(output[0][0] - output_1_same) < 0.01 else \"isnt\"}\")\n",
    "\n",
    "\n",
    "#what this does is x * wT + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bd3b7123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 8., 7., 5.],\n",
      "        [7., 6., 1., 5.],\n",
      "        [1., 4., 9., 5.],\n",
      "        [1., 5., 2., 3.],\n",
      "        [6., 6., 8., 7.]])\n",
      "tensor([[-0.7581,  0.0349,  1.3123, -1.4181,  1.1790],\n",
      "        [ 1.0783,  0.3211,  0.6872,  0.8963, -0.4345],\n",
      "        [ 0.8008,  1.5736, -1.0892,  0.0499, -1.3864],\n",
      "        [ 1.6806, -0.8455, -0.3553,  2.2667, -1.2862]])\n"
     ]
    }
   ],
   "source": [
    "#also, can use .numpy to turn tensor into numpy array\n",
    "#lets just see the effects of a linear transform on linear data:\n",
    "\n",
    "#in linalg, what does it mean to be transformed in this way? well it is a change in basis, functionally\n",
    "\n",
    "#suppose you have some matrix:\n",
    "torch.manual_seed(42)\n",
    "\n",
    "MATRIX = torch.randint(low=1,high=11,size=(5,4)).type(torch.float32)\n",
    "print(MATRIX)\n",
    "#and\n",
    "WEIGHTS = torch.randn_like(MATRIX).T\n",
    "print(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "78cd7df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901],\n",
      "        [0.8964, 0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n",
      "        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823, 0.6816],\n",
      "        [0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527, 0.0362],\n",
      "        [0.1852, 0.3734, 0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
      "        [0.0317, 0.2081, 0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
      "        [0.5846, 0.0332, 0.1387, 0.2422, 0.8155, 0.7932, 0.2783]])\n",
      "tensor([[1.8542],\n",
      "        [1.9611],\n",
      "        [2.2884],\n",
      "        [3.0481],\n",
      "        [1.7067],\n",
      "        [2.5290],\n",
      "        [1.7989]])\n"
     ]
    }
   ],
   "source": [
    "#HW:\n",
    "#1: random tensor shape 7,7\n",
    "torch.manual_seed(0)\n",
    "random_tensor = torch.rand(size=(7,7))\n",
    "print(random_tensor)\n",
    "\n",
    "#mat mult by another tensors size (1,7)\n",
    "another_random = torch.rand(size=(1,7))\n",
    "\n",
    "resulting_tensor = random_tensor.matmul(another_random.T)\n",
    "print(resulting_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
